{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bebcadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import requests\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f593f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "model = YOLO(\"C:/sameer/FYP_face_onyx/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# object classes\n",
    "classNames = [\"Hannan\", \"Arham\", \"Sameer\"]\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            # print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # class name\n",
    "            cls = int(box.cls[0])\n",
    "            isUnknown = True if confidence < 0.5 else False\n",
    "            # print(\"Class name -->\", 'Unknown' if confidence < 0.5 else classNames[cls])\n",
    "\n",
    "            # object details\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.putText(img, 'Unknown' if confidence < 0.5 else classNames[cls], org, font, fontScale, color, thickness)\n",
    "           \n",
    "            keys = {\n",
    "                'Hannan' : 'wPnHYXndB6fQkNmX83uKA4E1iP02',\n",
    "                'Arham' : 'vPXvYEjxf1Xb54HVHEHklVZUC9x2',\n",
    "                'Sameer' : '7UKgVpNtT2UYeKeM2PMPB6LCPjF2'\n",
    "                \n",
    "                 }\n",
    "\n",
    "            url = 'https://faceonyx-app-59085-default-rtdb.firebaseio.com/alerts.json'\n",
    "            current_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            custom_json = {\n",
    "                keys[classNames[cls]]:[\n",
    "                    {\n",
    "                        \"date\" : current_date,\n",
    "                        \"time\" : current_time,\n",
    "                        \"authorized\": True,\n",
    "                        \"user\": [classNames[cls]]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            custom_json = json.dumps(custom_json)\n",
    "            print(custom_json)\n",
    "            res = requests.patch(url, data = custom_json)\n",
    "            print(res)\n",
    "            #if not isUnknown:\n",
    "                # Code to trigger ignition event on response\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde0583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c30c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "keys = {\n",
    "    'Sameer' : '7UKgVpNtT2UYeKeM2PMPB6LCPjF2',\n",
    "    'Hannan' : 'wPnHYXndB6fQkNmX83uKA4E1iP02',\n",
    "    'Arham' : 'vPXvYEjxf1Xb54HVHEHklVZUC9x2'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ef69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a674ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12308f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import requests\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import json\n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "model = YOLO(\"C:/sameer/FYP_face_onyx/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# object classes\n",
    "classNames = [\"Hannan\", \"Arham\", \"Sameer\",\"unknown\"]\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # class name\n",
    "            cls = int(box.cls[0])\n",
    "            isUnknown = True if confidence < 0.5 else False\n",
    "            print(\"Class name -->\", 'Unknown' if confidence < 0.5 else classNames[cls])\n",
    "\n",
    "            # object details\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.putText(img, 'Unknown' if confidence < 0.5 else classNames[cls], org, font, fontScale, color, thickness)\n",
    "           \n",
    "           \n",
    "            #if not isUnknown:\n",
    "                # Code to trigger ignition event on response\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c1714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe67b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d841556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"C:/sameer/FYP_face_onyx/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Object classes\n",
    "classNames = [\"Hannan\", \"Arham\", \"Sameer\"]\n",
    "\n",
    "def process_image(img_path):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Error: The file does not exist at the path: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Check file permissions\n",
    "    if not os.access(img_path, os.R_OK):\n",
    "        print(f\"Error: The file cannot be read (permissions issue): {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Check if the image was successfully loaded\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to read the image from the path: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Resize the image if needed\n",
    "    max_width, max_height = 640, 640\n",
    "    h, w = img.shape[:2]\n",
    "    if h > max_height or w > max_width:\n",
    "        scaling_factor = min(max_width/w, max_height/h)\n",
    "        img = cv2.resize(img, (int(w*scaling_factor), int(h*scaling_factor)))\n",
    "\n",
    "    # Convert image to RGB if needed (YOLO models typically expect RGB input)\n",
    "    if img.shape[2] == 4:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "    elif img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run YOLO model\n",
    "    results = model(img)\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes:\n",
    "            for box in boxes:\n",
    "                # Extract bounding box coordinates\n",
    "                x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "                \n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "\n",
    "                # Confidence\n",
    "                confidence = box.conf[0]\n",
    "\n",
    "                # Class name\n",
    "                cls = int(box.cls[0])\n",
    "                class_name = 'Unknown' if confidence < 0.5 else classNames[cls]\n",
    "\n",
    "                # Draw class label\n",
    "                org = (x1, y1 - 10)  # Position text above the bounding box\n",
    "                cv2.putText(img, class_name, org, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "    # Display the image with bounding boxes and labels\n",
    "    cv2.imshow('Image', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))  # Convert RGB back to BGR for display\n",
    "    cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    # List of image paths\n",
    "    img_paths = [  # Example uploaded image path\n",
    "        \"C:/sameer/FYP_face_onyx/dataset/images/train/IMG_6127.JPEG\"\n",
    "    ]\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        process_image(img_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f654c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040368f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ab5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(\"C:/sameer/FYP_face_onyx/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Object classes\n",
    "classNames = [\"Hannan\", \"Arham\", \"Sameer\"]\n",
    "\n",
    "# Firebase keys\n",
    "keys = {\n",
    "    'Hannan': 'wPnHYXndB6fQkNmX83uKA4E1iP02',\n",
    "    'Arham': 'vPXvYEjxf1Xb54HVHEHklVZUC9x2',\n",
    "    'Sameer': '7UKgVpNtT2UYeKeM2PMPB6LCPjF2'\n",
    "}\n",
    "\n",
    "# Firebase URL\n",
    "url = 'https://faceonyx-app-59085-default-rtdb.firebaseio.com/alerts.json'\n",
    "\n",
    "def process_image(img_path):\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Error: The file does not exist at the path: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Check file permissions\n",
    "    if not os.access(img_path, os.R_OK):\n",
    "        print(f\"Error: The file cannot be read (permissions issue): {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Check if the image was successfully loaded\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to read the image from the path: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Resize the image if needed\n",
    "    max_width, max_height = 640, 640\n",
    "    h, w = img.shape[:2]\n",
    "    if h > max_height or w > max_width:\n",
    "        scaling_factor = min(max_width/w, max_height/h)\n",
    "        img = cv2.resize(img, (int(w*scaling_factor), int(h*scaling_factor)))\n",
    "\n",
    "    # Convert image to RGB if needed (YOLO models typically expect RGB input)\n",
    "    if img.shape[2] == 4:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "    elif img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run YOLO model\n",
    "    results = model(img)\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes:\n",
    "            for box in boxes:\n",
    "                # Extract bounding box coordinates\n",
    "                x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "                \n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "\n",
    "                # Confidence\n",
    "                confidence = box.conf[0]\n",
    "\n",
    "                # Class name\n",
    "                cls = int(box.cls[0])\n",
    "                class_name = 'Unknown' if confidence < 0.5 else classNames[cls]\n",
    "\n",
    "                # Draw class label\n",
    "                org = (x1, y1 - 10)  # Position text above the bounding box\n",
    "                cv2.putText(img, class_name, org, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "                # If the person is identified, send data to Firebase\n",
    "                if class_name != 'Unknown':\n",
    "                    current_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "                    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                    custom_json = {\n",
    "                        keys[class_name]: [\n",
    "                            {\n",
    "                                \"date\": current_date,\n",
    "                                \"time\": current_time,\n",
    "                                \"authorized\": True,\n",
    "                                \"user\": [class_name]\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    custom_json = json.dumps(custom_json)\n",
    "                    print(custom_json)\n",
    "                    res = requests.patch(url, data=custom_json)\n",
    "                    print(res)\n",
    "\n",
    "    # Display the image with bounding boxes and labels\n",
    "    cv2.imshow('Image', cv2.cvtColor(img, cv2.COLOR_RGB2BGR))  # Convert RGB back to BGR for display\n",
    "    cv2.waitKey(0)  # Wait for a key press to close the image window\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    # List of image paths\n",
    "    img_paths = [\n",
    "        \"C:/sameer/FYP_face_onyx/dataset/images/train/IMG_6725.JPEG\",\n",
    "        \"C:/sameer/FYP_face_onyx/dataset/images/train/IMG_6536.JPEG\",  # Example uploaded image path\n",
    "        \"C:/sameer/FYP_face_onyx/dataset/images/train/IMG_6186.JPEG\"\n",
    "    ]\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        process_image(img_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46173b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aedc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341e652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09635a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810d0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b4f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfffe61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763e1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741948f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd837def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed914042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e4dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e89322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99432a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605dc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79cc69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca7743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac33f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16b329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316aa988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5108dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
